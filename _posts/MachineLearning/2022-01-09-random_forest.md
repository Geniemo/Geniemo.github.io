---
title:  "[Machine Learning] 랜덤 포레스트"
excerpt: "Random forest"

categories:
  - Machine Learning

toc: true
toc_sticky: true
toc_label: "랜덤 포레스트"

last_modified_at: 2022-01-09
---

## 결정 트리와 앙상블

결정 트리는 이상적인 머신 러닝 모델이 되기에는 부정확합니다.

하지만 결정 트리를 응용하면 성능이 좋은 다른 모델들을 만들 수 있습니다.

결정 트리를 응용하는 대표적인 방법 중 하나는 앙상블(ensemble)이라는 방법이 있습니다.<br>
앙상블은 하나의 모델을 쓰는 대신 수많은 모델들을 이용해서 예측을 한 후<br>
여러 예측들을 합쳐서 종합적인 판단을 하는 것입니다.

## 랜덤 포레스트

랜덤 포레스트는 트리 앙상블 알고리즘 중 하나입니다.<br>
랜덤 포레스트는 수많은 결정 트리를 임의로 만들고 다수결 투표로 결과를 종합하는 알고리즘입니다.

랜덤 포레스트에서 임의성을 더하는 요소에는 아래 두가지가 더 있습니다.

> Bootstrapping

Bootstrapping은 갖고 있는 데이터 셋을 이용해서 조금 다른 데이터 셋을 만들어내는 방법입니다.

원래 데이터 셋에서 임의로 데이터들을 골라서 새로운 데이터들을 만듭니다.<br>
이 때, 그냥 조금 다른 새로운 데이터 셋을 만드는 것이 목적이므로 중복은 신경쓰지 않습니다.

이렇게 만든 데이터 셋을 Bootstrap 데이터 셋이라고 합니다.<br>
모든 모델을 정확히 똑같은 데이터 셋으로 학습시키면 결과의 다양성이 떨어질 수 있는데,<br>
Bootstrap 데이터셋을 이용해 각 모델을 서로 다른 데이터 셋으로 학습시켜서 이 문제를 해결할 수 있습니다.

이렇게 Bootstrap 데이터 셋을 만들어내고 모델들의 결정을 종합해서 예측하는 앙상블 기법을<br>
Bootstrap aggregating, 줄여서는 Bagging이라고 합니다.

> 결정 트리를 만드는 과정

결정 트리를 만들 때,<br>
앞선 포스트에서는 모든 속성들을 이용한 노드들의 지니 불순도를 구하고 가장 낮은 노드를 선택했지만,<br>
랜덤 포레스트를 만들 때에는 임의성을 더하기 위해서 모든 속성 중 임의로 몇 개를 고른 후에<br>
그 속성들을 이용하는 질문들 중 더 좋은 것을 선택합니다.

이렇게 매 노드를 만들 때 어느 정도는 임의성이 들어가기 때문에 수많은 서로 다른 결정 트리들이 나올 수 있습니다.

이런식으로 두 가지 임의성을 더해 엄청 많은 결정 트리들을 임의로 만드는 것이 랜덤 포레스트입니다.<br>
랜덤 포레스트를 이용해서 예측할 때에는 데이터를 랜덤 포레스트의 각 결정 트리에 각각 넣어준 후<br>
각 결정 트리가 결정하는 것을 바탕으로 다수결 투표로 결과를 도출해냅니다.

## scikit-learn으로 랜덤 포레스트 사용하기

<script src="https://gist.github.com/Geniemo/d8a79d7b775d0fabb7198b1f7edd030f.js"></script>

그런데 여기서, 랜덤 포레스트를 사용했지만 앞서 그냥 결정 트리 하나를 사용했을 때와<br>
점수가 같은 것을 알 수 있습니다.<br>
이에 대한 이유가 궁금하시다면 [여기](https://www.analyticsvidhya.com/blog/2020/05/decision-tree-vs-random-forest-algorithm/)를 참고하세요.