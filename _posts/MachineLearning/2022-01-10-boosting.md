---
title:  "[Machine Learning] 에다 부스트"
excerpt: "Adaboost"

categories:
  - Machine Learning

toc: true
toc_sticky: true
toc_label: "에다 부스트"

last_modified_at: 2022-01-09
---

## Boosting

부스팅은 또다른 앙상블 기법입니다.<br>
부스팅 역시 앙상블 기법이므로 여러 개의 모델을 씁니다.

부스팅은 일부러 성능이 안좋은 모델들을 사용합니다.<br>
Bagging과 마찬가지로 각 모델이 조금 다른 데이터를 써서 학습하는데,<br>
Bootstrap처럼 데이터를 임의로 만드는 게 아니라<br>
먼저 만든 모델들이 어떻게 예측을 했냐에 따라 뒤에 만드는 데이터 셋이 결정됩니다.

또한, 모델들의 예측을 종합할 때 단순히 투표를 하는 게 아니라<br>
성능이 좋은 모델의 예측을 더 반영합니다.

## 에다 부스트 (Adaboost)

에다 부스트에서도 수많은 결정 트리들을 만듭니다.<br>
에다 부스트에서는 깊은 결정 트리가 아니라 루트 노드 하나와 분류 노드 두 개를 갖는 얕은 결정 트리를 사용합니다.<br>
이런 식으로 하나의 질문과 그 질문에 대한 답으로 바로 예측을 하는 결정 트리를 나무의 그루터기를 의미하는 stump 라고 합니다.<br>
이런 식으로 만든 stump는 성능이 평균적으로 50%를 조금 넘는 정도로 안좋습니다.

그리고 에다 부스트에서는 부스팅 기법답게 각 모델이 사용하는 데이터 셋을 임의로 만들지 않습니다.<br>
어떤 데이터가 있고, 그걸 바탕으로 스텀프를 만들어서 분류를 했다고 하겠습니다.<br>
그럼 올바르게 분류된 데이터들이 있고, 틀리게 분류된 데이터들이 있겠죠?<br>
이것을 바탕으로 다음 스텀프에 쓸 데이터 셋을 만들 때에는<br>
올바르게 분류된 데이터들의 중요도를 낮추고, 틀리게 분류된 데이터들의 중요도를 높입니다.<br>
중요도가 높은 데이터들은 뒤에 만든 스텀프가 우선적으로 맞출 수 있게 합니다.

이런 식으로 각 스텀프는 전 스텀프의 실수를 바로잡는 방향으로 만들어지게 됩니다.

이렇게 수많은 스텀프들을 만든 후에는 종합적인 예측을 해야합니다.<br>
에다 부스트는 다수결의 원칙이 아니라 성능주의적 예측으로 합니다.<br>
예측을 종합할 때 성능이 좋은 스텀프의 의견 비중을 더 높게 반영한다는 것입니다.

## 스텀프 성능 계산하기

에다 부스트는 예측을 종합할 때 각 트리의 성능을 반영하기 때문에 트리를 만들 때마다 성능을 미리 계산해야 합니다.<br>
특정 스텀프의 성능은 아래와 같이 계산합니다.

\\[ \displaystyle \frac{1}{2}log(\frac{1 - total_error}{total_error}) \hbox{, total_error: 잘못 분류한 데이터들의 중요도의 합} \\]

그래프는 아래와 같습니다.

<script src="https://gist.github.com/Geniemo/a2d156482bf727f62b1e4aa393f4be0a.js"></script>

위 식은 \\(total\_error\\)가 1에 가까워질수록 작아지고, 0에 가까워질수록 커집니다.<br>
다른 말로 하면, 특정 스텀프의 성능은 \\(total\_error\\)가 1에 가까워질수록 안좋고, 0에 가까워질수록 좋다는 것입니다.

## 데이터 중요도 바꾸기

다음 스텀프가 학습할 데이터를 만들 때에는<br>
틀리게 분류한 데이터의 중요도를 높여주고,<br>
맞게 분류한 데이터의 중요도를 낮춰줘야 합니다.

틀리게 분류한 모든 데이터에 대해서는 아래와 같이 중요도를 바꿔줍니다.

\\[ weight_{new} = weight_{old} \times e^{P_{tree}}, \hbox{P_{tree}: 스텀프의 성능} \\]

제대로 분류한 모든 데이터에 대해서는 아래와 같이 중요도를 바꿔줍니다.

\\[ weight_{new} = weight_{old} \times e^{-P_{tree}}, \hbox{P_{tree}: 스텀프의 성능} \\]

이렇게 바꿔줬을 때 마지막으로 까먹으면 안되는 게 있습니다.<br>
중요도는 항상 다 더해서 1이 되어야 하므로 각 데이터의 중요도를 모든 중요도의 합으로 나눠줘서 비율이 조절되게 하는 것입니다.